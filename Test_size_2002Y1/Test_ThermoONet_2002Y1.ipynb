{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e0273-6153-4ac9-afba-88e0fb907e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.interpolate import interp1d\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from plyfile import PlyData, PlyElement\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.optimize import brentq\n",
    "import random\n",
    "\n",
    "from ThermoONet_architecture import Branch\n",
    "from ThermoONet_architecture import SELayer\n",
    "from ThermoONet_architecture import SELayer_w\n",
    "from ThermoONet_architecture import Branch1\n",
    "from ThermoONet_architecture import Branch2\n",
    "from ThermoONet_architecture import Branch3\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678acc16-e3e0-4030-8339-e92b7d8245c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensors = 128\n",
    "branch = Branch(num_sensors).cuda()\n",
    "# Read the trained network\n",
    "branch = torch.load(\"Network/network_accurate.pkl\")\n",
    "\n",
    "# Z-score parameters\n",
    "mean, std = 0.5216620832565283, 0.16037000058696135\n",
    "mean_p1, std_p1 = 5.587696141721031, 1.8642376418421138\n",
    "mean_p2, std_p2 = 0.9012508495757381, 0.057731154082425275\n",
    "mean_p3, std_p3 = 0.011181149021523971, 0.004995541538499874\n",
    "mean_p4, std_p4 = 16.542181636792183, 12.499430941576392\n",
    "mean_p5, std_p5 = 16.524861547108635, 12.931041392620573\n",
    "mean_p6, std_p6 = 0.45722424339279366, 0.306981614080625\n",
    "mean_p7, std_p7 = 0.058400414325008906, 0.030512679311208945\n",
    "mean_p8, std_p8 = 0.06281489233220064, 0.034735621144138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96cc9ad-aa4f-4a12-9d7e-ed81a721b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cometary size estimation from SOHO/SWAN observations\"\"\"\n",
    "# files1: Water production rate from SOHO/SWAN\n",
    "# files2: Orbit from JPL corresponding to SOHO/SWAN\n",
    "\n",
    "class Size_inverse():\n",
    "    def __init__(self, file1, file2):\n",
    "        self.file1, self.file2 = file1, file2\n",
    "    \n",
    "    def Z_Score(self, x):\n",
    "        mean = np.mean(x)\n",
    "        std = np.std(x)\n",
    "        return mean, std, (x-mean)/std\n",
    "\n",
    "    def Minmax(self, x):\n",
    "        min_x = np.min(x)\n",
    "        max_x = np.max(x)\n",
    "        x_norm = x/max_x\n",
    "        return min_x, max_x, x_norm\n",
    "\n",
    "    # Some functions\n",
    "    def ZHK(self, p_global3, p_ice3, u):\n",
    "        mb = 3e-26\n",
    "        kb = 1.38e-23\n",
    "        psi = 1/(1+0.14*p_global3/0.001)\n",
    "\n",
    "        a = 3.23e+12\n",
    "        b = 6134.6\n",
    "        c0 = 0.146\n",
    "        c1 = 0.854\n",
    "        c2 = 57.78\n",
    "        c3 = 11580\n",
    "\n",
    "        Pv = a*np.exp(-b/(u))\n",
    "        alpha = c0+c1/(1+np.exp(c2-c3/(u)))\n",
    "        Z_HK = psi*p_ice3*alpha*Pv*np.sqrt(mb/(2*np.pi*kb*(u)))\n",
    "        return Z_HK\n",
    "\n",
    "    def equator_rotation(self, theta, omega, pos):\n",
    "        cos_omega = np.cos(omega)\n",
    "        sin_omega = np.sin(omega)\n",
    "        rotation_matrices = np.array([\n",
    "                            [cos_omega, sin_omega, np.zeros_like(cos_omega)],\n",
    "                            [-sin_omega, cos_omega, np.zeros_like(cos_omega)],\n",
    "                            [np.zeros_like(cos_omega), np.zeros_like(cos_omega), np.ones_like(cos_omega)]])\n",
    "\n",
    "        rotation_matrix_z = rotation_matrices.transpose(2, 0, 1)\n",
    "\n",
    "        cos_theta = np.cos(np.pi/2-theta)\n",
    "        sin_theta = np.sin(np.pi/2-theta)\n",
    "        rotation_matrices = np.array([\n",
    "                            [cos_theta, np.zeros_like(theta), -sin_theta],\n",
    "                            [np.zeros_like(theta), np.ones_like(theta), np.zeros_like(theta)],\n",
    "                            [sin_theta, np.zeros_like(theta), cos_theta]])\n",
    "\n",
    "        rotation_matrix_y = rotation_matrices.transpose(2, 0, 1)\n",
    "\n",
    "        pos_new = np.sum(rotation_matrix_y*np.sum(rotation_matrix_z*pos.reshape(len(pos), 1, 3), \\\n",
    "                                                  axis=-1).reshape(len(pos), 1, 3), axis=-1)\n",
    "        return pos_new\n",
    "\n",
    "    def generate_ellipsoid_triangulation(self, a, b, c, num_points=16):\n",
    "        u = np.linspace(0, 2*np.pi, num_points)\n",
    "        v = np.linspace(0, np.pi, num_points)\n",
    "\n",
    "        x = a*np.outer(np.cos(u), np.sin(v))\n",
    "        y = b*np.outer(np.sin(u), np.sin(v))\n",
    "        z = c*np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "        points = np.array([x.flatten(), y.flatten(), z.flatten()]).T\n",
    "\n",
    "        hull = ConvexHull(points)\n",
    "        triangles = hull.simplices\n",
    "\n",
    "        return points, triangles\n",
    "\n",
    "    def utc_to_julian(self, utc_time):\n",
    "        if not isinstance(utc_time, datetime):\n",
    "            raise ValueError(\"must datetime object\")\n",
    "        julian_day = utc_time.toordinal()+1721424.5+(utc_time.hour + utc_time.minute/60+utc_time.second/3600)/24\n",
    "        return julian_day\n",
    "\n",
    "    def julian_to_utc(self, julian_day):\n",
    "        if not isinstance(julian_day, (float, int)):\n",
    "            raise ValueError(\"must float or int\")\n",
    "\n",
    "        z = int(julian_day+0.5)\n",
    "        f = julian_day+0.5-z\n",
    "        if z < 2299161:\n",
    "            a = z\n",
    "        else:\n",
    "            alpha = int((z-1867216.25)/36524.25)\n",
    "            a = z+1+alpha-int(alpha/4)\n",
    "\n",
    "        b = a+1524\n",
    "        c = int((b-122.1)/365.25)\n",
    "        d = int(365.25*c)\n",
    "        e = int((b-d)/30.6001)\n",
    "\n",
    "        day = b-d-int(30.6001 * e)+f\n",
    "        month = e-(1 if e < 14 else 13)\n",
    "        year = c-(4716 if month > 2 else 4715)\n",
    "\n",
    "        hour = int((f*24))\n",
    "        minute = int(((f*24)-hour)*60)\n",
    "        second = int((((f*24)-hour)*60-minute)*60)\n",
    "\n",
    "        return datetime(year, month, int(day), hour, minute, second)\n",
    "\n",
    "    def cartesian_to_spherical(self, x, y, z):\n",
    "        r = math.sqrt(x**2+y**2+z**2)\n",
    "        theta = math.acos(z/r)\n",
    "        phi = math.atan2(y, x)\n",
    "        if phi<0:\n",
    "            phi = 2*np.pi+phi\n",
    "        return r, theta, phi\n",
    "\n",
    "    def normal_vector(self, A, B, C):\n",
    "        AB = B-A\n",
    "        AC = C-A\n",
    "        nv = np.cross(AB, AC)\n",
    "        return nv/np.sqrt(np.sum(nv**2))\n",
    "\n",
    "    def center_vector(self, A, B, C):\n",
    "        Cx = (A[0]+B[0]+C[0])/3\n",
    "        Cy = (A[1]+B[1]+C[1])/3\n",
    "        Cz = (A[2]+B[2]+C[2])/3\n",
    "        return np.array([Cx, Cy, Cz])\n",
    "\n",
    "    def area_surface(self, A, B, C):\n",
    "        v1 = B-A\n",
    "        v2 = C-A\n",
    "        cross_product = np.cross(v1, v2)\n",
    "        area = 0.5*np.linalg.norm(cross_product)\n",
    "        return area\n",
    "\n",
    "    def fl(self, beta, yita, nvs):\n",
    "        # calculate the radiation flux function of every facet in spin axis coordinate system\n",
    "\n",
    "        # beta: the angle between the Sun and z-axis\n",
    "        # yita: the angle between the Sun and x-axis\n",
    "        # nvs: the normal vectors of facets\n",
    "\n",
    "        N = 128\n",
    "        sun = np.array([np.sin(beta)*np.cos(yita), np.sin(beta)*np.sin(yita), np.cos(beta)])\n",
    "        if np.sqrt(sun[0]**2+sun[1]**2)==0:\n",
    "            lo_sun = np.arccos(0)\n",
    "        else:\n",
    "            lo_sun = np.arccos(sun[0]/np.sqrt(sun[0]**2+sun[1]**2))\n",
    "        if yita > 180*np.pi/180:\n",
    "            if np.sqrt(sun[0]**2+sun[1]**2)==0:\n",
    "                lo_sun = 2*np.pi-np.arccos(0)\n",
    "            else:\n",
    "                lo_sun = 2*np.pi-np.arccos(sun[0]/np.sqrt(sun[0]**2+sun[1]**2))\n",
    "        sun_xy = np.sqrt(sun[0]**2+sun[1]**2)\n",
    "        sun = np.array([sun_xy*np.cos(lo_sun-np.linspace(0, 2*np.pi, N)), \\\n",
    "                        sun_xy*np.sin(lo_sun-np.linspace(0, 2*np.pi, N)), \\\n",
    "                        sun[2]*np.ones(N)]).T\n",
    "\n",
    "        function = np.dot(nvs, sun.T)\n",
    "        function[function<0] = 0\n",
    "\n",
    "        flist_ellipsoid = interp1d(np.linspace(0, 2*np.pi, N), function, kind='linear', axis=1)\n",
    "\n",
    "        return flist_ellipsoid\n",
    "    \n",
    "    def water_production(self, ars, nvs, df_list, orbit_whole, params):\n",
    "        orbit_co_whole = []\n",
    "        for j in range(len(orbit_whole)):\n",
    "            orbit_j = orbit_whole[j]\n",
    "            theta = params[10]\n",
    "            omega_1 = params[9]\n",
    "            orbit_co_mid = -self.equator_rotation(np.ones(len(orbit_j))*theta*np.pi/180, \\\n",
    "                                                 np.ones(len(orbit_j))*omega_1*np.pi/180, orbit_j[:, 1:4])\n",
    "\n",
    "            orbit_co = []\n",
    "            for i in range(len(orbit_j)):\n",
    "                orbit_co.append(self.cartesian_to_spherical(orbit_co_mid[i, 0], orbit_co_mid[i, 1], orbit_co_mid[i, 2]))\n",
    "            orbit_co = np.concatenate((df_list[j][:, 0][:, None], orbit_j[:, 0][:, None], np.array(orbit_co)), axis=-1)\n",
    "\n",
    "            orbit_co_whole.append(orbit_co)\n",
    "        orbit_co_whole = np.concatenate(orbit_co_whole, axis=0)\n",
    "        orbit_co_whole = orbit_co_whole[orbit_co_whole[:, 0].argsort()]\n",
    "\n",
    "        num_p = 12\n",
    "        num = len(orbit_co_whole)\n",
    "\n",
    "        zsj = 0\n",
    "        yita_list = np.linspace(0, 2*np.pi, num_p)\n",
    "        f_data = []\n",
    "        for i in range(num):\n",
    "            flist = self.fl(orbit_co_whole[i, -2], orbit_co_whole[i, -1], nvs)\n",
    "\n",
    "            for j in range(num_p):\n",
    "                f_for = flist(np.mod(np.linspace(0, 2*np.pi, 128)-yita_list[j], 2*np.pi))\n",
    "                f_data.append(f_for.reshape(len(f_for), 128))\n",
    "            zsj = zsj+1\n",
    "        f_data = np.array(f_data).reshape(zsj, num_p, len(nvs), 128)\n",
    "        f_test = torch.tensor(f_data).float().cuda()\n",
    "\n",
    "        omega_spin = 2*np.pi/(10*3600)\n",
    "\n",
    "        Te_list = []\n",
    "        p_list = []\n",
    "        deep_list = []\n",
    "        sign_arr = np.sign(orbit_co_whole[:, 0])\n",
    "        time_perihe = np.where(sign_arr[:-1] != sign_arr[1:])[0]+0\n",
    "        for i in range(num):\n",
    "            if i <= time_perihe:\n",
    "                zsj = -np.exp(np.linspace(orbit_co_whole[time_perihe, 2]/1.496e+8*params[0], \\\n",
    "                                          np.max(orbit_co_whole[:, 2]/1.496e+8)*2, 100))\n",
    "                zsj = (zsj-np.min(zsj))/(np.max(zsj)-np.min(zsj))*(params[1]-params[4])+params[4]\n",
    "                zsj_interp = interp1d(np.linspace(min(orbit_co_whole[:, 0]), \\\n",
    "                                                  orbit_co_whole[time_perihe, 0], 100).flatten(), zsj.flatten(), kind='linear')\n",
    "            else:\n",
    "                zsj = -np.exp(-np.linspace(orbit_co_whole[time_perihe, 2]/1.496e+8*params[2], \\\n",
    "                                           np.max(orbit_co_whole[:, 2]/1.496e+8)*2, 100))\n",
    "                zsj = (zsj-np.min(zsj))/(np.max(zsj)-np.min(zsj))*(params[3]-params[4])+params[4]\n",
    "                zsj_interp = interp1d(np.linspace(orbit_co_whole[time_perihe, 0], \\\n",
    "                                                  max(orbit_co_whole[:, 0]), 100).flatten(), zsj.flatten(), kind='linear')\n",
    "\n",
    "            p_global3 = zsj_interp(orbit_co_whole[i, 0])\n",
    "            deep_list.append(p_global3)\n",
    "\n",
    "        deep = np.array(deep_list)\n",
    "    \n",
    "        for i in range(num):\n",
    "            Guy_list = []\n",
    "            p_global1 = np.sqrt(np.sqrt((1-0.05)*1357/(orbit_co_whole[i, 2]/1.496e+8)**2))\n",
    "            p_global = [p_global1, 1, deep[i]]\n",
    "            p_dust = [params[8], params[6]]\n",
    "            p_ice = [8.388111692959722, params[7], params[5]]\n",
    "\n",
    "            p_ice[0] = np.sqrt((1-p_ice[-1])*p_dust[0]**2+p_ice[-1]*2100*920*omega_spin)\n",
    "\n",
    "            p_data = np.array([p_global[0], p_global[1], p_global[2], p_dust[0], p_ice[0], p_ice[2], p_dust[1], p_ice[1]])\n",
    "            Te_list.append(p_data[0]/(p_data[1]*5.67e-8)**(1/4))\n",
    "            p_data = ((p_data-np.array([mean_p1, mean_p2, mean_p3, mean_p4, mean_p5, mean_p6, mean_p7, mean_p8])) \\\n",
    "                           /np.array([std_p1, std_p2, std_p3, std_p4, std_p5, std_p6, std_p7, std_p8]))\n",
    "            p_list.append(p_data)\n",
    "        p_data = np.array(p_list)\n",
    "        Te = np.array(Te_list).reshape(num, 1)\n",
    "\n",
    "        p_test = torch.tensor(p_data).float().cuda()\n",
    "        output2 = branch.branch2(p_test[:, 1:8])\n",
    "        output3 = branch.branch3(p_test[:, 0].unsqueeze(1))\n",
    "        leakyrelu = nn.LeakyReLU(0.02)\n",
    "        output23 = leakyrelu(branch.se(torch.mul(output2, output3)+0.001))\n",
    "\n",
    "        WPR = []\n",
    "        for i in range(num):\n",
    "            Z_D_nump = []\n",
    "            for j in range(num_p):\n",
    "                output1 = branch.branch1(f_test[i, j])\n",
    "                output = ((torch.mean(output1*output23[i], dim=-1)+0.01)*std+mean).detach().cpu().numpy()\n",
    "                Guy = (output*Te[i]).reshape(1, len(f_for))\n",
    "                Guy[np.where(Guy<0)] = -Guy[np.where(Guy<0)]\n",
    "\n",
    "                Z_D = self.ZHK(deep[i], p_ice[-1], Guy)\n",
    "                Z_D = np.sum(Z_D*ars.flatten(), axis=-1)\n",
    "                Z_D_nump.append(Z_D)\n",
    "            WPR.append(np.mean(np.array(Z_D_nump))*1e+6/3e-26)\n",
    "        WPR_max = np.max(np.array(WPR))\n",
    "        WPR = np.array(WPR/WPR_max)\n",
    "        return WPR, WPR_max, deep\n",
    "\n",
    "    # Loss function\n",
    "    def objective_function(self, ars, nvs, df_list, orbit_whole, conditions, observed_data):\n",
    "        solution, _, _ = self.water_production(ars, nvs, df_list, orbit_whole, conditions)\n",
    "        mseloss = np.mean((np.abs(solution-observed_data)/observed_data))\n",
    "        return mseloss\n",
    "\n",
    "    # Simulated Annealing\n",
    "    def simulated_annealing(self, ars, nvs, df_list, orbit_whole, observed_data, current_conditions, max_iter=20, \\\n",
    "                            initial_temp=100, final_temp=1, cooling_rate=0.8):\n",
    "        loss_list = []\n",
    "        current_list = []\n",
    "        current_score = self.objective_function(ars, nvs, df_list, orbit_whole, current_conditions, observed_data)\n",
    "        # print(current_score)\n",
    "        best_conditions = current_conditions\n",
    "        initial_conditions = current_conditions\n",
    "        best_score = current_score\n",
    "\n",
    "        temperature = initial_temp\n",
    "        while temperature >= final_temp:\n",
    "            best_Me_score = []\n",
    "            for iteration in range(max_iter):\n",
    "                while True:\n",
    "                    new_conditions = [np.abs(current_conditions[i]+random.uniform(-initial_conditions[i]/3, initial_conditions[i]/3))\n",
    "                                      for i in range(len(current_conditions))]\n",
    "                    new_conditions[5] = np.abs(current_conditions[5]+random.uniform(-0.05, 0.05))\n",
    "                    new_conditions[-2] = current_conditions[-2]+random.uniform(-45, 45)\n",
    "                    new_conditions[-1] = current_conditions[-1]+random.uniform(-90, 90)\n",
    "\n",
    "                    pan1 = 0.01<=new_conditions[0]<=2\n",
    "                    pan2 = 0.001<=new_conditions[1]<=0.006\n",
    "                    pan3 = 0.01<=new_conditions[2]<=2\n",
    "                    pan4 = 0.001<=new_conditions[3]<=0.006\n",
    "                    pan5 = 0.001<=new_conditions[4]<=0.006\n",
    "                    pan6 = 0.01<=new_conditions[5]<=0.5\n",
    "                    pan7 = 0.04<=new_conditions[6]<=0.07\n",
    "                    pan8 = 0.04<=new_conditions[7]<=0.07\n",
    "                    pan9 = 5<=new_conditions[8]<=12\n",
    "                    pan10 = -90<=new_conditions[9]<=90\n",
    "                    pan11 = 0<=new_conditions[10]<=360\n",
    "                    pan12 = new_conditions[4]<new_conditions[1]\n",
    "                    pan13 = new_conditions[4]<new_conditions[3]\n",
    "                    pan14 = np.abs(new_conditions[1]-new_conditions[3])<=0.003\n",
    "                    if pan1&pan2&pan3&pan4&pan5&pan6&pan7&pan8&pan9&pan10&pan11&pan12&pan13&pan14:\n",
    "                        break\n",
    "\n",
    "                new_score = self.objective_function(ars, nvs, df_list, orbit_whole, new_conditions, observed_data)\n",
    "                # print('new_score:', new_score)\n",
    "                loss_list.append(new_score)\n",
    "\n",
    "                if new_score < current_score:\n",
    "                    current_conditions = new_conditions\n",
    "                    current_score = new_score\n",
    "                else: \n",
    "                    if random.random() < np.exp((current_score-new_score)*1e+3/temperature):\n",
    "                        current_conditions = new_conditions\n",
    "                        current_score = new_score\n",
    "                current_list.append(current_score)\n",
    "                if current_score < best_score:\n",
    "                    best_conditions = current_conditions\n",
    "                    best_score = current_score\n",
    "                else:\n",
    "                    current_conditions = best_conditions\n",
    "                    current_score = best_score\n",
    "\n",
    "            # print('best:', best_score, best_conditions)\n",
    "\n",
    "            temperature *= cooling_rate\n",
    "\n",
    "        return best_conditions, best_score\n",
    "    \n",
    "    def cal(self):\n",
    "        tab_files = []\n",
    "        tab_files.append(self.file1)\n",
    "\n",
    "        df_list = []\n",
    "        for tab_file in tab_files:\n",
    "            try:\n",
    "                df = pd.read_csv(tab_file, sep='\\t', header=None).to_numpy()\n",
    "                df_mid = []\n",
    "                for i in range(len(df)):\n",
    "                    df_mid_1 = list(map(float, df[i, 0][21:].split()))\n",
    "                    if df_mid_1[-1]<500 and df_mid_1[0]>-500:\n",
    "                        df_mid.append(df_mid_1)\n",
    "                df_list.append(np.array(df_mid)[::1])\n",
    "            except Exception as e:\n",
    "                print(f\"{e}\")\n",
    "        if len(tab_files) != 1:\n",
    "            df_whole = np.concatenate(df_list, axis=0)\n",
    "        else:\n",
    "            df_whole = df_list[0]\n",
    "        df_whole = df_whole[df_whole[:, 0].argsort()]\n",
    "\n",
    "        df_whole[:, -2] = df_whole[:, -2]*10**27\n",
    "        df_whole = df_whole[::1, :]\n",
    "        WPR_min, WPR_max, WPR_deal = self.Minmax(df_whole[:, -2])\n",
    "\n",
    "        df_list_plot = []\n",
    "        for tab_file in tab_files:\n",
    "            try:\n",
    "                df = pd.read_csv(tab_file, sep='\\t', header=None).to_numpy()\n",
    "                df_mid = []\n",
    "                for i in range(len(df)):\n",
    "                    df_mid_1 = list(map(float, df[i, 0][21:].split()))\n",
    "                    if df_mid_1[-1]<500 and df_mid_1[0]>-500: # 1995_o1\n",
    "                        df_mid.append(df_mid_1)\n",
    "                df_list_plot.append(np.array(df_mid)[::1])\n",
    "            except Exception as e:\n",
    "                print(f\"{e}\")\n",
    "        if len(tab_files) != 1:\n",
    "            df_whole_plot = np.concatenate(df_list_plot, axis=0)\n",
    "        else:\n",
    "            df_whole_plot = df_list_plot[0]\n",
    "        df_whole_plot = df_whole_plot[df_whole_plot[:, 0].argsort()]\n",
    "\n",
    "        df_whole_plot[:, -2] = df_whole_plot[:, -2]*10**27\n",
    "        df_whole_plot = df_whole_plot[::1, :]\n",
    "        \n",
    "        # Shape\n",
    "        a1, b1, c1 = 1.5, 1, 1\n",
    "        gui = np.max([a1, b1, c1])\n",
    "        a, b, c = a1/gui, b1/gui, c1/gui\n",
    "        vertices, triangles = self.generate_ellipsoid_triangulation(a, b, c)\n",
    "\n",
    "        surface_element = []\n",
    "        for i in range(len(triangles)):\n",
    "            surface_element.append([vertices[int(triangles[i, 0]), :], vertices[int(triangles[i, 1]), :], \\\n",
    "                                    vertices[int(triangles[i, 2]), :]])\n",
    "        surface_element = np.array(surface_element)\n",
    "\n",
    "        surface_element_list = []\n",
    "        for i in range(len(surface_element)):\n",
    "            a2 = np.sum(surface_element[i, 0, :]-surface_element[i, 1, :])\n",
    "            b2 = np.sum(surface_element[i, 0, :]-surface_element[i, 2, :])\n",
    "            c2 = np.sum(surface_element[i, 1, :]-surface_element[i, 2, :])\n",
    "            if a2!=0 and b2!=0 and c2!=0:\n",
    "                surface_element_list.append(surface_element[i, :, :])\n",
    "        surface_element = np.array(surface_element_list)\n",
    "\n",
    "        # 计算法向量、面积\n",
    "        nvs = []\n",
    "        ces = []\n",
    "        ars = []\n",
    "        for i in range(len(surface_element)):\n",
    "            nv = self.normal_vector(surface_element[i, 0, :], surface_element[i, 1, :], surface_element[i, 2, :])\n",
    "            ce = self.center_vector(surface_element[i, 0, :], surface_element[i, 1, :], surface_element[i, 2, :])\n",
    "            ar = self.area_surface(surface_element[i, 0, :], surface_element[i, 1, :], surface_element[i, 2, :])\n",
    "            if np.dot(nv, surface_element[i, 0, :])<0:\n",
    "                nv = -nv\n",
    "            nvs.append(nv)\n",
    "            ces.append(ce)\n",
    "            ars.append(ar)\n",
    "        nvs = np.array(nvs)\n",
    "        ces = np.array(ces)\n",
    "        ars = np.array(ars).reshape(len(surface_element), 1)\n",
    "        \n",
    "        tab_files = []\n",
    "        tab_files.append(self.file2)\n",
    "\n",
    "        orbit_whole = []\n",
    "        looktabel = []\n",
    "        for j in range(len(tab_files)):\n",
    "            filename = tab_files[j]\n",
    "            with open(filename, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                lines = [line.strip() for line in lines]\n",
    "            orbit = []\n",
    "            for i in range(len(lines)-1):\n",
    "                orbit.append(list(map(float, lines[i+1][21:].split()))[1:])\n",
    "            orbit = np.array(orbit)\n",
    "\n",
    "            time_orb = []\n",
    "            for i in range(len(lines)-1):\n",
    "                year = list(map(int, lines[i+1][:4].split()))[0]\n",
    "                month = list(map(int, lines[i+1][5:7].split()))[0]\n",
    "                day = list(map(int, lines[i+1][8:10].split()))[0]\n",
    "                hour = list(map(int, lines[i+1][11:13].split()))[0]\n",
    "                minute = list(map(int, lines[i+1][14:16].split()))[0]\n",
    "                second = list(map(int, lines[i+1][17:19].split()))[0]\n",
    "                if second == 60:\n",
    "                    second -= 1\n",
    "                cos_time = datetime(year=year, month=month, day=day, hour=hour, minute=minute, second=second)\n",
    "                time_orb.append(self.utc_to_julian(cos_time))\n",
    "            time_orb = np.array(time_orb)[:, None]\n",
    "            orbit = np.concatenate((time_orb, orbit), axis=-1)\n",
    "\n",
    "            t_co = np.linspace(0, 1, len(orbit))\n",
    "            orbit_interp = interp1d(t_co, orbit, axis=0)\n",
    "\n",
    "            helio = np.sqrt(np.sum(orbit[:, 1:4]**2, axis=-1))/1.496e+8\n",
    "            helio_interp = interp1d(t_co, helio, axis=0)\n",
    "\n",
    "            num = len(df_list[j])\n",
    "            t_data = []\n",
    "            for i in range(num):\n",
    "                def target(t):\n",
    "                    return helio_interp(t)-df_list[j][i, 1]\n",
    "                if df_list[j][i, 1] == np.min(df_list[j][:, 1]):\n",
    "                    t_solution = t_co[np.argmin(helio)]\n",
    "                else:\n",
    "                    try:\n",
    "                        if df_list[j][i, 0]<0:\n",
    "                            t_solution = brentq(target, 0, t_co[np.argmin(helio)])\n",
    "                        else:\n",
    "                            t_solution = brentq(target, t_co[np.argmin(helio)], 1)\n",
    "                    except:\n",
    "                        aaaa = 1\n",
    "                t_data.append(t_solution)\n",
    "            t_data = np.array(t_data)\n",
    "\n",
    "            orbit_use = orbit_interp(t_data)\n",
    "            orbit_whole.append(orbit_use)\n",
    "\n",
    "        theta = -50\n",
    "        omega = 275\n",
    "        orbit_co_whole = []\n",
    "        for j in range(len(orbit_whole)):\n",
    "            orbit_j = orbit_whole[j]\n",
    "            orbit_co_mid = -self.equator_rotation(np.ones(len(orbit_j))*theta*np.pi/180, \\\n",
    "                                             np.ones(len(orbit_j))*omega*np.pi/180, orbit_j[:, 1:4])\n",
    "            orbit_co = []\n",
    "            for i in range(len(orbit_j)):\n",
    "                orbit_co.append(self.cartesian_to_spherical(orbit_co_mid[i, 0], orbit_co_mid[i, 1], orbit_co_mid[i, 2]))\n",
    "            orbit_co = np.concatenate((df_list[j][:, 0][:, None], orbit_j[:, 0][:, None], np.array(orbit_co)), axis=-1)\n",
    "            orbit_co_whole.append(orbit_co)\n",
    "        orbit_co_whole = np.concatenate(orbit_co_whole, axis=0)\n",
    "        orbit_co_whole = orbit_co_whole[orbit_co_whole[:, 0].argsort()]\n",
    "        \n",
    "        size_list = []\n",
    "        for i in range(30):\n",
    "            observed_data = WPR_deal\n",
    "            initial_conditions = np.array([1, 0.005, 1, 0.005, 0.003, 0.1, 0.05, 0.05, 7, 0, 180])\n",
    "            estimated_conditions, score = self.simulated_annealing(ars, nvs, df_list, orbit_whole, observed_data, initial_conditions)\n",
    "\n",
    "            water_c_test, max_test, deep_test = self.water_production(ars, nvs, df_list, orbit_whole, estimated_conditions)\n",
    "            size_mid = math.pow(np.sqrt(WPR_max/max_test)**3/1.5**2, 1/3)*2\n",
    "            print('size = ', size_mid, 'MAPE = ', score)\n",
    "            size_list.append(size_mid)\n",
    "        size_list = np.array(size_list)\n",
    "        size = np.mean(size_list)\n",
    "        return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4907fed-8716-4e91-890e-e2e8f0bb330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_files1 = 'water_c_2002_y1_juels_hovorcem.tab'\n",
    "tab_files2 = '2002_y1_juels_hovorcem.txt'\n",
    "\n",
    "Size_cal = Size_inverse(tab_files1, tab_files2)\n",
    "Size_cal.cal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a3e34-4bda-4c25-b072-b83bb155cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is designed for the inversion of the nucleus size of C/2002 Y1. \n",
    "# If applied to other comets, the input files must be modified, \n",
    "# and the activity peak position in the class should be adjusted according to the water curve peak. \n",
    "# Otherwise, the code will fail to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b085640-4583-42ea-9658-de200aef6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the numerous fitting parameters, the annealing algorithm in this code runs for 30 cycles, \n",
    "# and the average value is taken as the reference for the inverted size. \n",
    "# The number of cycles or the parameters within the annealing algorithm can be modified to achieve a more precise size inversion.\n",
    "# However, considering the trade-off between precision and computational time, we recommend avoiding excessive iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
